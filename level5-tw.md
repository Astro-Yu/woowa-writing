GitHub Actions로 수동 배포 탈출하기: 주니어 개발자의 CI/CD 자동화 구축기

# 0. 개요 (들어가며)
팀 프로젝트를 진행하면서, 잦은 배포와 수정 사항이 발생할 때마다 반복적인 수동 배포 과정은 팀의 생산성을 저해하는 큰 요인이었습니다. 이 문제를 해결하기 위해 GitHub Actions를 도입하여 기존의 수동 CI/CD 프로세스를 완전 자동화된 파이프라인으로 개선했습니다.

이 글은 저희가 왜 자동화가 필요했는지, 그리고 GitHub Actions를 사용해 어떻게 CI/CD 파이프라인을 구축했는지 그 과정과 노하우, 그리고 발생했던 문제들을(트러블 슈팅) 공유합니다.

# 1. 왜 CI/CD 자동화가 필요했을까요?
모든 자동화의 시작은 '반복적인 수작업의 고통'에서 비롯됩니다. 저희 팀이 겪었던 불편함과 이를 자동화로 해결했을 때의 이점을 정리했습니다.

## 1.1. 수동 배포, 무엇이 문제였나? (The Pain Point)
자동화 도입 전, 저희 팀의 배포 시나리오는 다음과 같았습니다.

로컬 빌드: Git에서 main 브랜치의 최신 코드를 로컬로 pull 받아 Docker 이미지를 빌드합니다.

- 문제점 1: 개발자마다 pull 받은 시점이 다르면, 서로 다른 코드 베이스로 이미지를 빌드할 수 있습니다.

- 문제점 2: 로컬에서 테스트나 빌드가 실패했을 때, 이 상황이 다른 팀원들에게 즉각 공유되지 않습니다.

  - 이미지 푸시: 로컬에서 빌드한 이미지를 Docker Hub에 push 합니다.

  - 서버 접속 및 배포: EC2 배포 서버에 ssh로 직접 접속합니다.

- 문제점 3: 불필요하게 서버에 직접 접속해야 하므로 관리 포인트가 늘어나고 보안상 위험이 있습니다.

  - 컨테이너 실행: Docker Hub에서 이미지를 pull 받고, 기존 컨테이너를 중지시킨 뒤 새 컨테이너를 실행합니다.

- 문제점 4: latest 태그 대신 실수로 다른 버전의 이미지를 pull 할 위험이 있습니다.

- 문제점 5: 기존 컨테이너를 먼저 내리지 않으면 포트 충돌 에러가 발생하며, 이는 곧 **서비스 중단(Downtime)**을 의미합니다.

이 모든 과정의 근본적인 문제점은 다음과 같습니다.

시간 낭비: 배포 때마다 이 모든 과정을 사람이 반복적으로 수행해야 합니다.

인적 오류 (Human Error): 관리 포인트가 늘어날수록 사람이 실수할 확률은 기하급수적으로 높아집니다.

대응 속도: 긴급 버그 수정(핫픽스)이나 롤백이 필요할 때도 이 긴 과정을 다시 거쳐야 하므로 대응이 치명적으로 느려집니다.

## 1.2. 자동 CI/CD 도입의 이점
위의 문제점들은 자동화된 파이프라인을 구축함으로써 대부분 해결되었습니다.

신뢰할 수 있는 통합: 모든 코드는 GitHub Actions라는 하나의 가상 환경에서 테스트되고 빌드됩니다. (개발자 PC 환경에 의존하지 않음)

단일 코드 베이스 보장: 항상 main 브랜치의 최신 코드를 기준으로 이미지가 생성됩니다.

개발자 경험(DX) 향상: 더 이상 배포를 위해 개발자가 서버에 직접 접속할 필요가 없습니다.

신속한 배포 및 롤백: 배포, 롤백, 핫픽스 모두 'Push' 또는 'Click' 한 번으로 빠르고 안정적으로 수행됩니다.

# 2. CI/CD 개념 바로잡기
저희는 파이프라인을 구축하기 전에 CI/CD의 목적을 명확히 정의했습니다.

## CI (Continuous Integration, 지속적 통합)
목적: 여러 개발자가 작성한 코드를 하나의 코드 베이스에 지속적으로 통합하고, 해당 코드를 바탕으로 문제없는 실행 파일(결과물)을 만드는 과정입니다.

한 줄 요약: **"무엇을 배포할지"** 결정합니다.

저희 팀의 CI: 저희는 'EC2 서버에서 사용할 Docker 이미지'를 최종 결과물로 정의했습니다. 따라서 CI의 범위는 [코드 통합 → 테스트 → Docker 이미지 빌드 및 Docker Hub 푸시]까지입니다.

## CD (Continuous Deployment/Delivery, 지속적 배포/제공)
목적: CI 과정에서 만든 결과물(Docker 이미지 등)을 실제 서버로 전달(Delivery)하고 배포(Deployment)하는 과정입니다.

한 줄 요약: **"어떻게 배포할지"** 결정합니다.

Delivery vs. Deployment:

Delivery (제공): 결과물을 서버에 전달하되, 실제 배포(실행)는 사람이 수동으로 승인합니다.

Deployment (배포): 결과물을 서버에 전달하고, 배포(실행)까지 완전 자동으로 진행합니다. 저희 팀은 main 브랜치 기준 완전 자동 배포(Deployment)를 채택했습니다.

💡 저희 팀의 핵심 결정: 왜 이미지를 CI에서 빌드했는가?
이미지를 만드는 과정(Image Build)을 CD가 아닌 CI에 포함한 데는 명확한 이유가 있습니다.

효율성: CI에서 한 번 잘 빌드된 이미지를 여러 배포 서버(개발, 스테이징, 프로덕션)에서 가져다 쓰기만 하면 됩니다. 만약 CD 과정에서 이미지를 빌드한다면, 각 서버가 배포될 때마다 매번 이미지를 빌드해야 하므로 시간이 낭비됩니다.

일관성 및 신뢰성: CI에서 테스트를 통과한 단 하나의 코드 스냅샷으로 이미지가 만들어집니다. 이는 모든 배포 환경에서 "CI를 통과한 동일한 이미지"가 실행됨을 보장하여 신뢰성을 높입니다.

# 3. 실전: GitHub Actions로 CI/CD 구축하기
저희 팀이 main 브랜치를 기준으로 구축한 CI/CD 파이프라인의 상세 로직입니다.

## 3.1. CI 파이프라인: "무엇을 배포할지" (Test & Build)
CI는 '언제' 실행되는지에 따라 두 가지 작업을 수행합니다.

A. main 브랜치를 향한 PR(Pull Request) 발생 시: test Job 실행
main 브랜치에 합쳐지기 전, 기존 코드를 망가뜨리지 않는지 **검증(Test)**만 합니다.

Checkout: 워크플로우 가상 환경으로 소스 코드를 내려받습니다.

Cache Gradle dependencies: 빌드 속도 최적화를 위해 .gradle 의존성을 캐시합니다. ( build.gradle 내용이 바뀔 때만 새로 다운로드)

Setup Gradle: 빌드 환경을 설정합니다.

Build with Gradle: ./gradlew clean test 명령어로 테스트만 실행합니다.

B. main 브랜치에 Push(Merge) 발생 시: build-and-push Job 실행
main 브랜치에 합쳐졌을 때, **배포 가능한 최종 Docker 이미지(결과물)**를 만듭니다.

(A와 1~3번 동일)

Build with Gradle: ./gradlew clean build를 실행합니다. ( build 명령어는 test를 포함하므로 테스트가 먼저 실행됩니다.)

Set up Docker Buildx & Login: Docker 이미지를 빌드하고 Docker Hub에 로그인할 준비를 합니다.

Build and push Docker image:

이미지를 빌드하고 Docker Hub에 푸시합니다.

이때 플랫폼을 linux/arm64로 명시합니다. (트러블 슈팅 섹션 참고)

태그는 latest와 식별용 SHA 태그 두 개를 사용합니다.

Save image tag to file: 방금 푸시한 SHA 태그를 파일로 저장하고, GitHub Artifact에 업로드합니다. (CD 과정에서 이 태그를 사용합니다.)

## 3.2. CD 파이프라인: "어떻게 배포할지" (Deploy)
CD는 CI와 완전히 분리되어, CI가 성공적으로 끝났을 때만 실행됩니다.

트리거: CI 워크플로우("Prod Server CI")가 main 브랜치에서 성공적으로 완료되었을 때 실행됩니다. (테스트나 빌드 실패 시 배포 X)

실행 환경: Self-hosted Runner (배포할 EC2 서버에서 직접 실행)

CD 과정은 결국 EC2 서버 내부에서 Docker 명령어를 실행해야 합니다. GitHub이 제공하는 가상 환경이 아니라, 우리 EC2 서버에 설치된 self-hosted runner가 이 Job을 받아 직접 수행하도록 설정했습니다.

deploy Job 상세 로직
Login to Docker Hub: Docker Hub에 로그인합니다.

Stop and remove existing container: 기존에 실행 중이던 구버전 컨테이너를 중지하고 삭제합니다. (이 부분에서 서비스 중단이 발생합니다.)

Download artifact: CI 과정에서 Artifact에 업로드했던 '이미지 태그 파일'을 다운로드합니다.

Extract deploy tag: 파일에서 정확한 SHA 태그를 읽어 환경 변수로 설정합니다.

Pull latest image: 해당 태그를 가진 Docker 이미지를 pull 합니다.

Deploy with Docker Compose: docker-compose.yml 파일을 사용하여 다운로드한 이미지로 새 컨테이너를 실행합니다.

Prune old images: pull 받고 남은 구버전 이미지들을 삭제하여 서버 용량을 확보합니다.

# 4. 트러블 슈팅 (Troubleshooting)
파이프라인 구축이 항상 순탄했던 것은 아닙니다. 저희가 겪었던 주요 문제와 해결 과정입니다.

## 4.1. Docker 이미지 플랫폼 불일치 (amd64 vs. arm64)
문제: CI는 성공했지만 EC2에서 이미지를 실행하려 할 때 exec format error가 발생했습니다.

원인: GitHub Actions의 기본 러너는 amd64 아키텍처입니다. 저희가 사용한 EC2 인스턴스(AWS Graviton)는 arm64였습니다. GitHub 러너에서 빌드된 이미지는 amd64 기반이므로 arm64 서버에서 실행되지 않았습니다.

해결: docker/build-push-action에서 platforms 옵션을 명시하여 타겟 아키텍처(arm64)용 이미지를 빌드하도록 강제했습니다.

```YAML

- name: Build and push Docker image
  uses: docker/build-push-action@v5
  with:
    # ... (생략)
    push: true
    platforms: linux/arm64 # 타겟 플랫폼 명시
    # ... (생략)
```

## 4.2. CI 시간 과다 소요 (8분 이상)
문제: CI가 한 번 실행되는데 8분 이상 걸려 개발 피드백 속도가 매우 느려졌습니다.

원인:

불필요한 멀티 플랫폼(amd64, arm64 동시) 빌드를 하고 있었습니다.

test Job과 build Job에서 각각 의존성을 다운로드하여 중복된 다운로드가 발생했습니다.

해결:

플랫폼을 arm64로 단일화했습니다.

Gradle Cache를 도입하여, 의존성이 변경되지 않았다면 캐시에서 가져오도록 변경했습니다. (현재 2~3분 내외로 단축)

## 4.3. (초기) CI 경합 상태 문제
문제: 초기에 dev 브랜치로 향하는 여러 feat 브랜치 PR들이 동시에 CI를 실행할 때, 서로 다른 코드가 합쳐지기 전에 빌드되어 배포 이미지가 덮어쓰기 되는 문제가 있었습니다.

해결: 파이프라인 전략을 명확히 수정했습니다.

PR은 **테스트(검증)**만 수행합니다.

오직 main 브랜치(성공적으로 Merge된 코드)만이 배포 가능한 최종 이미지를 빌드할 자격을 가집니다.

이로써 배포되는 이미지는 항상 main 브랜치의 코드임을 보장하게 되었습니다.

# 5. (부록) 왜 Docker를 사용했는가?
애초에 왜 이렇게 Docker 이미지를 고집했을까요?

"제 컴퓨터에선 됐는데요?" 문제 해결: Docker는 OS, JDK, 라이브러리 등 모든 환경을 이미지 하나에 통합합니다. 개발자 환경, GitHub Actions 서버, EC2 서버 환경이 모두 달라도, Docker 이미지만 실행하면 동일한 환경이 보장됩니다.

배포 편의성: 서버에서는 복잡한 설정 없이 이미지만 pull 받아 실행하면 됩니다.

확장성: 서버가 100대로 늘어나도, 100대의 서버가 모두 동일한 이미지를 실행하면 됩니다.

롤백 편의성: 배포에 문제가 생겼을 때, 이전 버전의 이미지 태그로 다시 실행하기만 하면 즉시 롤백이 가능합니다.

# 6. 결론 및 다음 단계
수동 배포의 고통에서 벗어나 자동화된 CI/CD 파이프라인을 구축한 것은 '신속함'과 '안정성'이라는 두 마리 토끼를 잡는 경험이었습니다. 개발자는 이제 코드에만 집중하고, 배포는 GitHub Actions가 알아서 처리해 주니 팀의 생산성이 크게 향상되었습니다.

물론 저희의 파이프라인이 완벽하진 않습니다. CD 과정에서 컨테이너를 중지하고 재시작할 때 **수 초간의 서비스 중단(Downtime)**이 발생합니다.

# 🚀 추가 학습 및 개선 키워드
무중단 배포 (Zero-Downtime Deployment):

현재의 Stop and Remove 방식은 다운타임을 유발합니다.

Blue/Green 배포나 Rolling Update 전략을 도입하여 서비스 중단 없이 새 버전을 배포하는 방법을 다음 목표로 하고 있습니다. (예: Nginx 리버스 프록시를 이용한 포트 스위칭)

GitHub Actions: Reusable Workflows: 여러 레포지토리에서 공통 CI/CD 로직을 사용해야 할 때, 워크플로우를 재사용하여 중복을 제거할 수 있습니다.

Secrets 관리: self-hosted runner에 민감한 정보(DB 패스워드 등)를 더 안전하게 주입하기 위해 AWS Secrets Manager 또는 HashiCorp Vault와 같은 전문 도구 사용을 고려할 수 있습니다.